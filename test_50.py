"""
Test avec 50 entreprises pour valider le systÃ¨me avant traitement complet
"""

import pandas as pd
from main_search import process_companies_batch, analyze_results, save_results_incrementally
from datetime import datetime
import time

def test_50_companies():
    """
    Test avec les 50 premiÃ¨res entreprises du fichier
    """
    print("ğŸ§ª TEST AVEC 50 ENTREPRISES")
    print("=" * 50)
    
    # Charger le fichier original
    try:
        df = pd.read_csv("data/face_raw.csv")
        print(f"ğŸ“„ Fichier chargÃ©: {len(df)} entreprises au total")
    except Exception as e:
        print(f"âŒ Erreur lors du chargement: {e}")
        return
    
    # Prendre les 50 premiÃ¨res entreprises
    sample_df = df.head(50).copy()
    
    print(f"ğŸ“‹ Test avec {len(sample_df)} entreprises:")
    print(f"   RÃ©partition par taille:")
    taille_counts = sample_df['Taille d\'entreprise'].value_counts()
    for taille, count in taille_counts.items():
        print(f"     {taille}: {count} entreprises")
    
    print(f"\nğŸ” DÃ©marrage de la recherche...")
    print(f"â±ï¸  Estimation: ~3-5 minutes")
    
    start_time = time.time()
    
    # Traiter par lots de 10 pour avoir des retours rÃ©guliers
    batch_size = 10
    all_results = []
    
    for start_idx in range(0, len(sample_df), batch_size):
        batch_num = start_idx // batch_size + 1
        total_batches = (len(sample_df) + batch_size - 1) // batch_size
        
        print(f"\nğŸ”„ Lot {batch_num}/{total_batches} (entreprises {start_idx + 1} Ã  {min(start_idx + batch_size, len(sample_df))})")
        
        batch_results = process_companies_batch(sample_df, start_idx, batch_size)
        all_results.append(batch_results)
        
        # Sauvegarder les rÃ©sultats intermÃ©diaires
        if all_results:
            combined_results = pd.concat(all_results, ignore_index=True)
            save_results_incrementally(combined_results, "data/test_50_results_partial.csv")
            
            # Statistiques rapides
            found = len(combined_results[combined_results['Statut_Recherche'] == 'TrouvÃ©'])
            total_processed = len(combined_results)
            print(f"   ğŸ“Š Progression: {found}/{total_processed} trouvÃ©es ({found/total_processed*100:.1f}%)")
        
        # Pause entre les lots (plus courte pour le test)
        if start_idx + batch_size < len(sample_df):
            print(f"   â¸ï¸  Pause 1s...")
            time.sleep(1)
    
    # Combiner tous les rÃ©sultats
    if all_results:
        final_results = pd.concat(all_results, ignore_index=True)
        
        # Calculer le temps total
        elapsed_time = time.time() - start_time
        
        # Sauvegarde finale
        save_results_incrementally(final_results, "data/test_50_results_final.csv")
        
        print(f"\n" + "=" * 50)
        print(f"ğŸ‰ TEST TERMINÃ‰ !")
        print(f"â±ï¸  Temps total: {elapsed_time:.1f} secondes")
        print(f"âš¡ Vitesse: {len(sample_df)/elapsed_time:.1f} entreprises/seconde")
        
        # Analyse dÃ©taillÃ©e des rÃ©sultats
        analyze_results(final_results)
        
        # Analyse par taille d'entreprise
        print(f"\nğŸ“Š ANALYSE PAR TAILLE D'ENTREPRISE:")
        for taille in final_results['Taille_Original'].unique():
            subset = final_results[final_results['Taille_Original'] == taille]
            found = len(subset[subset['Statut_Recherche'] == 'TrouvÃ©'])
            total = len(subset)
            print(f"   {taille}: {found}/{total} trouvÃ©es ({found/total*100:.1f}%)")
        
        # Effectifs trouvÃ©s
        effectifs_avec_donnees = final_results[
            (final_results['Statut_Recherche'] == 'TrouvÃ©') & 
            (final_results['Tranche_Effectifs_Code'].notna()) &
            (final_results['Tranche_Effectifs_Code'] != '')
        ]
        
        print(f"\nğŸ“ˆ EFFECTIFS DISPONIBLES:")
        print(f"   Entreprises avec effectifs: {len(effectifs_avec_donnees)}")
        
        if len(effectifs_avec_donnees) > 0:
            print(f"   RÃ©partition des effectifs:")
            effectifs_counts = effectifs_avec_donnees['Effectifs_Description'].value_counts()
            for effectif, count in effectifs_counts.head(8).items():
                print(f"     {effectif}: {count} entreprises")
        
        # Estimation pour le traitement complet
        total_companies = len(df)
        estimated_time = (elapsed_time / len(sample_df)) * total_companies
        estimated_minutes = estimated_time / 60
        
        print(f"\nğŸš€ ESTIMATION POUR LE TRAITEMENT COMPLET:")
        print(f"   Entreprises totales: {total_companies}")
        print(f"   Temps estimÃ©: {estimated_minutes:.1f} minutes")
        print(f"   Taux de succÃ¨s attendu: ~{len(final_results[final_results['Statut_Recherche'] == 'TrouvÃ©'])/len(final_results)*100:.1f}%")
        
        print(f"\nâœ… Fichiers gÃ©nÃ©rÃ©s:")
        print(f"   ğŸ“„ data/test_50_results_final.csv")
        print(f"   ğŸ“„ data/test_50_results_partial.csv")
        
        return final_results
        
    else:
        print("âŒ Aucun rÃ©sultat obtenu")
        return None

if __name__ == "__main__":
    print("ğŸš€ DÃ©marrage du test avec 50 entreprises...")
    results = test_50_companies()
    
    if results is not None:
        print(f"\nğŸ¯ Le systÃ¨me est prÃªt pour le traitement complet !")
        print(f"   Pour lancer le traitement complet:")
        print(f"   uv run python main_search.py")
    else:
        print(f"\nâŒ ProblÃ¨mes dÃ©tectÃ©s, vÃ©rifier la configuration")